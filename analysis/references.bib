@article {MimnoE3441,
	author = {Mimno, David and Blei, David M. and Engelhardt, Barbara E.},
	title = {Posterior predictive checks to quantify lack-of-fit in admixture models of latent population structure},
	volume = {112},
	number = {26},
	pages = {E3441--E3450},
	year = {2015},
	doi = {10.1073/pnas.1412301112},
	publisher = {National Academy of Sciences},
	abstract = {Bayesian models, including admixture models, are a powerful framework for articulating complex assumptions about large-scale genetic data; such models are widely used to explore data or to study population-level statistics of interest. However, we assume that a Bayesian model does not oversimplify the complexities in the data, to the point of invalidating our analyses. Here, we develop and study procedures for quantitatively evaluating admixture models of genetic data. Using four large genetic studies, we demonstrate that model checking should be an important part of the modern genetic data analysis pipeline. Our methods help to support inferences drawn from recovered population structure, to protect scientists from being misled by a misspecified model class, and to point scientists toward useful model extensions.Admixture models are a ubiquitous approach to capture latent population structure in genetic samples. Despite the widespread application of admixture models, little thought has been devoted to the quality of the model fit or the accuracy of the estimates of parameters of interest for a particular study. Here we develop methods for validating admixture models based on posterior predictive checks (PPCs), a Bayesian method for assessing the quality of fit of a statistical model to a specific dataset. We develop PPCs for five population-level statistics of interest: within-population genetic variation, background linkage disequilibrium, number of ancestral populations, between-population genetic variation, and the downstream use of admixture parameters to correct for population structure in association studies. Using PPCs, we evaluate the quality of the admixture model fit to four qualitatively different population genetic datasets: the population reference sample (POPRES) European individuals, the HapMap phase 3 individuals, continental Indians, and African American individuals. We found that the same model fitted to different genomic studies resulted in highly study-specific results when evaluated using PPCs, illustrating the utility of PPCs for model-based analyses in large genomic studies.},
	issn = {0027-8424},
	URL = {https://www.pnas.org/content/112/26/E3441},
	eprint = {https://www.pnas.org/content/112/26/E3441.full.pdf},
	journal = {Proceedings of the National Academy of Sciences}
}

@article{Gelman,
 ISSN = {10170405, 19968507},
 URL = {http://www.jstor.org/stable/24306036},
 abstract = {This paper considers Bayesian counterparts of the classical tests for goodness of fit and their use in judging the fit of a single Bayesian model to the observed data. We focus on posterior predictive assessment, in a framework that also includes conditioning on auxiliary statistics. The Bayesian formulation facilitates the construction and calculation of a meaningful reference distribution not only for any (classical) statistic, but also for any parameter-dependent "statistic" or discrepancy. The latter allows us to propose the realized discrepancy assessment of model fitness, which directly measures the true discrepancy between data and the posited model, for any aspect of the model which we want to explore. The computation required for the realized discrepancy assessment is a straightforward byproduct of the posterior simulation used for the original Bayesian analysis. We illustrate with three applied examples. The first example, which serves mainly to motivate the work, illustrates the difficulty of classical tests in assessing the fitness of a Poisson model to a positron emission tomography image that is constrained to be nonnegative. The second and third examples illustrate the details of the posterior predictive approach in two problems: estimation in a model with inequality constraints on the parameters, and estimation in a mixture model. In all three examples, standard test statistics (either a χ2 or a likelihood ratio) are not pivotal: the difficulty is not just how to compute the reference distribution for the test, but that in the classical framework no such distribution exists, independent of the unknown model parameters.},
 author = {Andrew Gelman and Xiao-Li Meng and Hal Stern},
 journal = {Statistica Sinica},
 number = {4},
 pages = {733--760},
 publisher = {Institute of Statistical Science, Academia Sinica},
 title = {POSTERIOR PREDICTIVE ASSESSMENT OF MODEL FITNESS VIA REALIZED DISCREPANCIES},
 volume = {6},
 year = {1996}
}


@article{Roswell,
author = {Roswell, Michael and Dushoff, Jonathan and Winfree, Rachael},
title = {A conceptual guide to measuring species diversity},
journal = {Oikos},
volume = {130},
number = {3},
pages = {321-338},
keywords = {coverage, Hill numbers, rarefaction, rarity},
doi = {https://doi.org/10.1111/oik.07202},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/oik.07202},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/oik.07202},
abstract = {Three metrics of species diversity – species richness, the Shannon index and the Simpson index – are still widely used in ecology, despite decades of valid critiques leveled against them. Developing a robust diversity metric has been challenging because, unlike many variables ecologists measure, the diversity of a community often cannot be estimated in an unbiased way based on a random sample from that community. Over the past decade, ecologists have begun to incorporate two important tools for estimating diversity: coverage and Hill diversity. Coverage is a method for equalizing samples that is, on theoretical grounds, preferable to other commonly used methods such as equal-effort sampling, or rarefying datasets to equal sample size. Hill diversity comprises a spectrum of diversity metrics and is based on three key insights. First, species richness and variants of the Shannon and Simpson indices are all special cases of one general equation. Second, richness, Shannon and Simpson can be expressed on the same scale and in units of species. Third, there is no way to eliminate the effect of relative abundance from estimates of any of these diversity metrics, including species richness. Rather, a researcher must choose the relative sensitivity of the metric towards rare and common species, a concept which we describe as ‘leverage.' In this paper we explain coverage and Hill diversity, provide guidelines for how to use them together to measure species diversity, and demonstrate their use with examples from our own data. We show why researchers will obtain more robust results when they estimate the Hill diversity of equal-coverage samples, rather than using other methods such as equal-effort sampling or traditional sample rarefaction.},
year = {2021}
}


@article{Jost,
author = {Jost, Lou},
title = {Entropy and diversity},
journal = {Oikos},
volume = {113},
number = {2},
pages = {363-375},
doi = {https://doi.org/10.1111/j.2006.0030-1299.14714.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2006.0030-1299.14714.x},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.2006.0030-1299.14714.x},
abstract = {Entropies such as the Shannon–Wiener and Gini–Simpson indices are not themselves diversities. Conversion of these to effective number of species is the key to a unified and intuitive interpretation of diversity. Effective numbers of species derived from standard diversity indices share a common set of intuitive mathematical properties and behave as one would expect of a diversity, while raw indices do not. Contrary to Keylock, the lack of concavity of effective numbers of species is irrelevant as long as they are used as transformations of concave alpha, beta, and gamma entropies. The practical importance of this transformation is demonstrated by applying it to a popular community similarity measure based on raw diversity indices or entropies. The standard similarity measure based on untransformed indices is shown to give misleading results, but transforming the indices or entropies to effective numbers of species produces a stable, easily interpreted, sensitive general similarity measure. General overlap measures derived from this transformed similarity measure yield the Jaccard index, Sørensen index, Horn index of overlap, and the Morisita–Horn index as special cases.},
year = {2006}
}


 @misc{wikipedia_diversity,
 title={Diversity index}
, url={https://en.wikipedia.org/wiki/Diversity_index}, journal={Wikipedia}
, publisher={Wikimedia Foundation}
, year={2021}
, month={Apr}} 


