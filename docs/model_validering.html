<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Model validation</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<link rel="icon" href="https://github.com/workflowr/workflowr-assets/raw/master/img/reproducible.png">
<!-- Add a small amount of space between sections. -->
<style type="text/css">
div.section {
  padding-top: 12px;
}
</style>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
      </style>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">DataProject</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="Diversity.html">Diversity</a>
</li>
<li>
  <a href="Function_usage.html">Functions</a>
</li>
<li>
  <a href="model_validering.html">Model validation</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/nbendsen/DataProject">
    <span class="fa fa-github"></span>
     
    Source code
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Model validation</h1>

</div>


<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-report" data-toggle="collapse" data-target="#workflowr-report">
<span class="glyphicon glyphicon-list" aria-hidden="true"></span> workflowr <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span>
</button>
</p>
<div id="workflowr-report" class="collapse">
<ul class="nav nav-tabs">
<li class="active">
<a data-toggle="tab" href="#summary">Summary</a>
</li>
<li>
<a data-toggle="tab" href="#checks"> Checks <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span> </a>
</li>
<li>
<a data-toggle="tab" href="#versions">Past versions</a>
</li>
</ul>
<div class="tab-content">
<div id="summary" class="tab-pane fade in active">
<p>
<strong>Last updated:</strong> 2021-04-19
</p>
<p>
<strong>Checks:</strong> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> 6 <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span> 1
</p>
<p>
<strong>Knit directory:</strong> <code>DataProject - model validation/</code> <span class="glyphicon glyphicon-question-sign" aria-hidden="true" title="This is the local directory in which the code in this file was executed."> </span>
</p>
<p>
This reproducible <a href="http://rmarkdown.rstudio.com">R Markdown</a> analysis was created with <a
  href="https://github.com/jdblischak/workflowr">workflowr</a> (version 1.6.2). The <em>Checks</em> tab describes the reproducibility checks that were applied when the results were created. The <em>Past versions</em> tab lists the development history.
</p>
<hr>
</div>
<div id="checks" class="tab-pane fade">
<div id="workflowr-checks" class="panel-group">
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRMarkdownfilestronguncommittedchanges"> <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span> <strong>R Markdown file:</strong> uncommitted changes </a>
</p>
</div>
<div id="strongRMarkdownfilestronguncommittedchanges" class="panel-collapse collapse">
<div class="panel-body">
<p>The R Markdown file has unstaged changes. To know which version of the R Markdown file created these results, you’ll want to first commit it to the Git repo. If you’re still working on the analysis, you can ignore this warning. When you’re finished, you can run <code>wflow_publish</code> to commit the R Markdown file and build the HTML.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongEnvironmentstrongempty"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Environment:</strong> empty </a>
</p>
</div>
<div id="strongEnvironmentstrongempty" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! The global environment was empty. Objects defined in the global environment can affect the analysis in your R Markdown file in unknown ways. For reproduciblity it’s best to always run the code in an empty environment.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSeedstrongcodesetseed20210322code"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Seed:</strong> <code>set.seed(20210322)</code> </a>
</p>
</div>
<div id="strongSeedstrongcodesetseed20210322code" class="panel-collapse collapse">
<div class="panel-body">
<p>The command <code>set.seed(20210322)</code> was run prior to running the code in the R Markdown file. Setting a seed ensures that any results that rely on randomness, e.g. subsampling or permutations, are reproducible.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSessioninformationstrongrecorded"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Session information:</strong> recorded </a>
</p>
</div>
<div id="strongSessioninformationstrongrecorded" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Recording the operating system, R version, and package versions is critical for reproducibility.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongCachestrongnone"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Cache:</strong> none </a>
</p>
</div>
<div id="strongCachestrongnone" class="panel-collapse collapse">
<div class="panel-body">
<p>Nice! There were no cached chunks for this analysis, so you can be confident that you successfully produced the results during this run.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongFilepathsstrongrelative"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>File paths:</strong> relative </a>
</p>
</div>
<div id="strongFilepathsstrongrelative" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Using relative paths to the files within your workflowr project makes it easier to run your code on other machines.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRepositoryversionstrongahrefhttpsgithubcomnbendsenDataProjecttree596ee03dc06e2f2351093ec0b3f562377a5cdad7targetblank596ee03a"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Repository version:</strong> <a href="https://github.com/nbendsen/DataProject/tree/596ee03dc06e2f2351093ec0b3f562377a5cdad7" target="_blank">596ee03</a> </a>
</p>
</div>
<div id="strongRepositoryversionstrongahrefhttpsgithubcomnbendsenDataProjecttree596ee03dc06e2f2351093ec0b3f562377a5cdad7targetblank596ee03a" class="panel-collapse collapse">
<div class="panel-body">
<p>
Great! You are using Git for version control. Tracking code development and connecting the code version to the results is critical for reproducibility.
</p>
<p>
The results in this page were generated with repository version <a href="https://github.com/nbendsen/DataProject/tree/596ee03dc06e2f2351093ec0b3f562377a5cdad7" target="_blank">596ee03</a>. See the <em>Past versions</em> tab to see a history of the changes made to the R Markdown and HTML files.
</p>
<p>
Note that you need to be careful to ensure that all relevant files for the analysis have been committed to Git prior to generating the results (you can use <code>wflow_publish</code> or <code>wflow_git_commit</code>). workflowr only checks the R Markdown file, but you know if there are other scripts or data files that it depends on. Below is the status of the Git repository when the results were generated:
</p>
<pre><code>
Ignored files:
    Ignored:    .Rhistory
    Ignored:    .Rproj.user/
    Ignored:    analysis/.Rhistory

Untracked files:
    Untracked:  figure/Animation.Rmd/unnamed-chunk-11-1.gif

Unstaged changes:
    Modified:   analysis/Animation.Rmd
    Modified:   analysis/model_validering.rmd

</code></pre>
<p>
Note that any generated files, e.g. HTML, png, CSS, etc., are not included in this status report because it is ok for generated content to have uncommitted changes.
</p>
</div>
</div>
</div>
</div>
<hr>
</div>
<div id="versions" class="tab-pane fade">

<p>
These are the previous versions of the repository in which changes were made to the R Markdown (<code>analysis/model_validering.rmd</code>) and HTML (<code>docs/model_validering.html</code>) files. If you’ve configured a remote Git repository (see <code>?wflow_git_remote</code>), click on the hyperlinks in the table below to view the files as they were in that past version.
</p>
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
File
</th>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
<th>
Message
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/nbendsen/DataProject/blob/6c0e88a7bfbd9c36e25d48491bbb1a309477d4b6/analysis/model_validering.rmd" target="_blank">6c0e88a</a>
</td>
<td>
GitHub
</td>
<td>
2021-04-15
</td>
<td>
Add files via upload
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/nbendsen/DataProject/1bfbb028da6b72fa5c1e0c104b13bf880ea2e226/docs/model_validering.html" target="_blank">1bfbb02</a>
</td>
<td>
GitHub
</td>
<td>
2021-04-14
</td>
<td>
Add files via upload
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/nbendsen/DataProject/f1737141417ab177317f192f8bb619ec5fd6b00f/docs/model_validering.html" target="_blank">f173714</a>
</td>
<td>
GitHub
</td>
<td>
2021-04-14
</td>
<td>
Add files via upload
</td>
</tr>
</tbody>
</table>
</div>
<hr>
</div>
</div>
</div>
<h1>
Assumption
</h1>
<p>Before going into the details of this validation, it is important to state that one huge assumption is made. For this validation to make sense we assume that the result coming from our model does not lie far away from the result coming from the observed cover data. Hence, we assume that we can use a test statistic of the observed cover data to validate our model. If the test statistic from the observed cover data in general are in an acceptable interval from the test statistics we would get when applying our method, we will accept the model.</p>
<h1>
Posterior predictive checks
</h1>
<p>To validate our model we will apply the technique of posterior predictive checks [2]. In a given plot we have obtained a posterior distribution for each specie that have a <span class="math inline">\(1\)</span> in the corresponding presence/absence data for this plot. These posterior distributions are estimated using the observed data.</p>
<p></br></p>
<p>For a given specie in a given plot the posterior distribution is given by the equation:</p>
<p><span class="math display">\[
\text{posterior} \sim Beta(a+y,b+n-y)
\]</span> <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are the parameters from the prior distribution for that specie. <span class="math inline">\(y\)</span> is taken from the cover data, and is, together with <span class="math inline">\(n\)</span>, the parameters from the likelihood for a given specie in a given plot. Hence <span class="math inline">\(y\)</span> is number of pins the specie is hit by in the plot, and n is the total number of pins used in the plot. In the NOVANA dataset <span class="math inline">\(n=16\)</span>. <br/></p>
Using the distributions we can generate a new cover dataset for the given plot by drawing one sample from the posterior distribution for each specie that we know are present in the plot. For each specie we draw a sample, which is in this case a number of how many pins the specie is hit by in the given plot. <br/> After this will we apply some test statistic on the generated cover data for the plot. We repeat this process a 1000 times, and compare the test statistic on the observed cover data (not applying our model) to the distribution of the test statistics of the generated data. <br/> The idea behind posterior predictive checks is that, if the model assumption are appropriate, the generated data will look like the observed data viewed through the chosen test statistic. </br> Below we visually inspect the first three plots in the dataset to see if the observed test statistic is extreme.
<p>
<p/>
<p>Besides doing visually inspections of the histograms we also calculate the tail-area probability which we call the posterior predictive p-value [3]. If we let <span class="math inline">\(T(y)\)</span> be the observed test statistic and <span class="math inline">\(T(y^{rep})\)</span> be the test statistics of the generated data we calculate the posterior predictive p-value as <span class="math display">\[
\text{posterior predictive p-value} = 2\cdot \min\Big(P(T(y^{rep}) \geq T(y))\text{ ,  } P(T(y^{rep}) \leq T(y))\Big)
\]</span> Small p-value close to zero indicate that the observed test statistic is not very likely relative to the generated data and the posterior predictive check suggests that the model is misspecified with respect to the test statistic. In our case, we have chosen a threshold at <span class="math inline">\(0.05\)</span> meaning that if the p-value is above 0.05, the model is said to be appropriate for the given plot. <br><br> As test statistic we use the shannon index: <span class="math display">\[
\text{shannon index = }- \Sigma_{i = 1}^Sp_i\cdot \ln(p_i)
\]</span> and we work with the same data as previous <a href="data_6230.html">link</a>.</p>
<pre class="r"><code>#Here we load the datasets for habitat 6230 in year 2014

cover &lt;- read.csv(&quot;data/cover_data_6230_year2014.csv&quot;)

freq &lt;- read.csv(&quot;data/frekvens_data_6230_year2014.csv&quot;)

abiotiske &lt;- read.csv(&quot;data/abiotiske_data_6230_year2014.csv&quot;)</code></pre>
<pre class="r"><code>#We remove the first 4 columns, as they are not species
cover_data &lt;- cover[,4:ncol(cover)]
freq_data &lt;- freq[,4:ncol(freq)]</code></pre>
<p>Examples:</p>
<pre class="r"><code>#First plot
ppc(1, freq_data, cover_data)</code></pre>
<p><img src="figure/model_validering.rmd/unnamed-chunk-5-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#Second plot
ppc(2, freq_data, cover_data)</code></pre>
<p><img src="figure/model_validering.rmd/unnamed-chunk-6-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#Third plot
ppc(3, freq_data, cover_data)</code></pre>
<p><img src="figure/model_validering.rmd/unnamed-chunk-7-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>All posterior predictive p-values are big in the above histograms which suggests that the model is appropriate for the first three plots. If we run the posterior predictive check on all plots we get the number of posterior predictive p-values that are less than 0.05 to be</p>
<pre class="r"><code>sum(pval &lt; 0.05)</code></pre>
<pre><code>[1] 102</code></pre>
<p>Total number of plots</p>
<pre class="r"><code>nrow(cover)</code></pre>
<pre><code>[1] 1232</code></pre>
<p>We can then calculate the proportion of plots, with a p-value less than 0.05</p>
<pre class="r"><code>sum(pval &lt; 0.05)/nrow(cover)</code></pre>
<pre><code>[1] 0.08279221</code></pre>
<p>The proportion of p-values that is less than 0.05 is 0.0827 for this dataset, and that is not a lot higher than the expected 0.05. This indicates that our model does lie too far from the observed test static which means, under the assumptions stated in beginning, our model is valid.</p>
<p><br><br></p>
<p>In each iteration for each blot we calculated a shanon index and a simpsons index with respect to our model.</p>
<pre class="r"><code>generated_shannon &lt;- read.csv(&quot;data/shannon_df.csv&quot;)[,1:1000]</code></pre>
<pre class="r"><code>generated_simpson &lt;- read.csv(&quot;data/simpson_df.csv&quot;)[,1:1000]</code></pre>
<p>We can now calculate the mean values for each plot, witch is done by taking the mean for each row. This is done for both simpson and shannon index.</p>
<pre class="r"><code>generated_shannon$mean &lt;- rowMeans(generated_shannon)</code></pre>
<pre class="r"><code>generated_simpson$mean &lt;- rowMeans(generated_simpson)</code></pre>
<p>For each plot we calculate the sum of the rows in the cover data set:</p>
<pre class="r"><code>cover_data$total &lt;- rowSums(cover_data)</code></pre>
<p>Using the sum for each plot we can now calculate the shannon index for each plot, just using the observed data.</p>
<pre class="r"><code>cover_data$shannon &lt;- rowSums(-cover_data[,1:ncol(cover_data)-1]/cover_data$total*log(cover_data[,1:ncol(cover_data)-1]/cover_data$tota),na.rm = TRUE)</code></pre>
<p>We now plot the shannon indexes calculated using only the observed data against the mean shannon index from the generated data calculated using our model:</p>
<pre class="r"><code>pval$cover_data_shannon &lt;- cover_data$shannon
pval$generated_shannon_mean &lt;- generated_shannon$mean </code></pre>
<p><img src="figure/model_validering.rmd/unnamed-chunk-20-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>It can be seen here that the mean of the generated data is higher than that of shannon index calculated only on the cover data for most of the plots. This effect is largest for the plots with the lowest shannon index, and seems to disappear for the plots with the largest shannon index. The colour in the plot indicated whether or not the posterior predictive p-val is less than 0.05 for a given plot. This again shows us that our model changes the shannon index the most for plot with a low shannon index. A reason for this could be that the shannon index is not linear, so to go from 2 to 3 in the shannon index requires a bigger change than to go from 1 to 2, as described in <a href="diversity.html">diversity</a>. To account for this will we try to plot the hill number calculated using the shannon index. The hill-shannon diversity account for this problem so we can try to look at that instead.</p>
<p>To calculate the hill-shannon diversity we use the Hill-diversity with <span class="math inline">\(l\)</span> approching 0 for the shannon index, as described in <a href="diversity.html">diversity</a>.</p>
<p><span class="math display">\[
\text{Hill diversity = }\left( \sum_{i=1}^{S} p_i (r_i)^{l}\right)^{1/l}
\]</span></p>
<p>We calculate this for all the generated shannon indexes and then take their mean value to compare against the observed cover hill-shannon diversity. This gives us the plot:</p>
<pre class="r"><code>pval$hill_mean &lt;- hill_number$mean2
pval$hill_cover &lt;- exp(cover_data$shannon)</code></pre>
<p><img src="figure/model_validering.rmd/unnamed-chunk-23-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>When looking at the same plot, but with hill-shannon diversity instead of shannon index, can it be seen that the large variation that were in the lower end of the shannon index is gone. This can indicate that when comparing our method against the observed cover data, we don’t see a larger change at lower diversity that at higher diversity. The disparity we can see in the plot with shannon index can therefor more be attributed to the non linearity of the shannon index than our model.</p>
<p>Users who wish to use our method for updating the cover data using presence/absence data, should be aware that our method can give significant higher shannon index values for plot with a small shannon index.</p>
<p>Using the sum for each plot we can now calculate the simpsons index for each plot, just using the observed data.</p>
<pre class="r"><code>cover_data$simpson &lt;- rowSums((cover_data[,1:(ncol(cover_data)-2)]/cover_data$total)^2)</code></pre>
<p>We now plot the simpsons indexes calculated using only the observed data against the mean shannon index calculated using our model:</p>
<pre class="r"><code>plot(cover_data$simpson, generated_simpson$mean)
abline(0,1, lwd = 3, col = &quot;blue&quot;)</code></pre>
<p><img src="figure/model_validering.rmd/unnamed-chunk-25-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>The simpson index looks similar to the shannon index, with the values in one end being close to the observed cover simpson index, while there is greater variance in the other end.</p>
<h1>
Code implementation
</h1>
<pre class="r"><code>library(fitdistrplus)</code></pre>
<pre class="r"><code>#We read the cover data and the presence/absense data without the first 4 columns, as they do not cotains information on species

cover_data &lt;- cover[,4:ncol(cover)]
freq_data &lt;- freq[,4:ncol(freq)]
  
#We make a dataframa for the parameters of the prior distribution for each plot, so it is possible to save the parameteres, and not calculate them when making the posteriror for each plot. Each row will contain the number/name of the specie and its corresponding parameters for the prior 

beta_fit &lt;- data.frame(matrix(ncol = 3, nrow = 0))

# We name the columns in the 
colnames(beta_fit) &lt;- c(&quot;species&quot;,&quot;a&quot;, &quot;b&quot;)</code></pre>
<pre class="r"><code>#Here we calculate the parameters for the priror distributions of each specie:
for (specie in colnames(cover_data)) {
  #First we normalise. Since there is in total used 16 pins for each plot, we will devide the entries in the cover data by 16
  beta_data &lt;- cover_data[,specie]/16
  
  #Now we remove the plots where the specie is not present. This can be done by using the information from the presence, absense data. If it        contains a 1, then the specie is present in the plot, if 0 it is absent. 
  beta_data &lt;- beta_data[freq_data[[specie]] == 1]
    
  #If the specie is not present in any of the plots, we do not have information to make a prior distribution for it, and will just give it parameters a=0 and b=0 as seen in the else clause.
  if (length(unique(beta_data)) &gt; 1) {
    #We use the method of moments to fit the prior beta distribution
    beta_data_fitted &lt;- fitdist(beta_data, &quot;beta&quot;, method = &quot;mme&quot;)
    
    #The parameters are added to the dataframe
    beta_fit[nrow(beta_fit) + 1,] &lt;- c(specie, beta_data_fitted$estimate[1], beta_data_fitted$estimate[2])
      
  }
  else {
    beta_fit[nrow(beta_fit) + 1,] &lt;- c(specie, 0,0)
    
  }
}</code></pre>
<pre class="r"><code>#n is the row number of the plot we are working with
n &lt;- 1

#We define which species are in present in the plot
species_spotted_in_frekvens &lt;- colnames(freq_data[c(freq_data[n,]  == 1)])

#We define which species are present in the present/absent dataset but are not seen in the cover dataset
not_in_cover &lt;- setdiff(species_spotted_in_frekvens,colnames(cover_data))

#We remove the species, that at present in the plots in the present/absent data, but are not observed in any plots in the cover data
species_spotted_in_frekvens &lt;- setdiff(species_spotted_in_frekvens, not_in_cover)

# we remove the columns, that are not representing species
observed &lt;- cover_data[n,c(species_spotted_in_frekvens)]

tmp &lt;- observed[observed &gt; 0]
T_static &lt;- -sum(tmp/sum(observed) * log((tmp/sum(observed))))

#We make a dataframe to save the parameters of the posterior for each spotted specie in the plot
new_beta &lt;- data.frame(matrix(ncol = 3, nrow = 0))
  
colnames(new_beta) &lt;- c(&quot;species&quot;,&quot;a&quot;, &quot;b&quot;) 

for (species_spotted in species_spotted_in_frekvens ) {
      
  #We define the parameters for the posterior 
      alpha_post &lt;- as.numeric(beta_fit[beta_fit$species == species_spotted,]$a) + cover_data[[species_spotted]][n] 
    beta_post &lt;-  as.numeric(beta_fit[beta_fit$species == species_spotted,]$b) + 16 - cover_data[[species_spotted]][n]
    
      #If the parameters are to small, we change them to 0, since R has a hard time working with them
      alpha_post &lt;- ifelse(alpha_post &lt; 1e-10, 0, alpha_post)
      beta_post &lt;- ifelse(beta_post &lt; 1e-10,0, beta_post)
      
      #We add the parameters to the dataframe
      new_beta[nrow(new_beta) + 1,] &lt;- c(species_spotted, alpha_post, beta_post)}

#We make a vector, to save the shannon indexes produces in each iteration
shannon &lt;- c()

for (i in 1:1000){
  
  #Vector for saving the random generated values from the posterior of each specie
  values &lt;- c()
  for (ele in species_spotted_in_frekvens){
    #These are the parameters, for the posterior of the specie
    a &lt;- as.numeric(new_beta[new_beta$species == ele,]$a)
    b &lt;- as.numeric(new_beta[new_beta$species ==ele,]$b)
    
    # We draw a random number from a beta distribution with the parameters for that specie and add it to the vector
    values &lt;- c(values, rbeta(1,a,b))
    
    
  }
  #We remove the values that are to small
  tmp &lt;- values[ values &gt; 0.00001]
  total &lt;- sum(tmp)
  
  #We calculate the shannon index
  shannon &lt;- c(shannon,-sum(tmp/total * log((tmp/total)))) 
  
}

min_val &lt;- min(T_static, min(shannon)) - 0.1
max_val &lt;- max(T_static, max(shannon)) + 0.1

n &lt;- length(shannon)
pvalue &lt;- min(sum(shannon&gt;= T_static)/n, sum(shannon&lt;= T_static)/n)

#This is the code that produces the histogram over the generated data
hist(shannon, xlim = c(min_val, max_val), main = sprintf(&quot;Histogram of simulated shannon indexes for plot %d&quot;, n), xlab = &quot;Shannon indexes&quot;)
legend(&quot;topright&quot;, legend = &quot;Red line is observed shannon index&quot;)
abline(v = T_static, col = &quot;red&quot; )</code></pre>
<h1>
References
</h1>
<ul>
<li>
[1] <a href="https://www.pnas.org/content/112/26/E3441#ref-19" class="uri">https://www.pnas.org/content/112/26/E3441#ref-19</a>
</li>
<li>
[2] POSTERIOR PREDICTIVE ASSESSMENT OF MODEL FITNESS VIA REALIZED DISCREPANCIES by Andrew Gelman, Xiao-Li Meng and Hal Stern
</li>
</ul>
<p><br><br><br><br></p>
<br>
<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-sessioninfo" data-toggle="collapse" data-target="#workflowr-sessioninfo" style="display: block;">
<span class="glyphicon glyphicon-wrench" aria-hidden="true"></span> Session information
</button>
</p>
<div id="workflowr-sessioninfo" class="collapse">
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 4.0.3 (2020-10-10)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 19042)

Matrix products: default

locale:
[1] LC_COLLATE=English_United Kingdom.1252 
[2] LC_CTYPE=English_United Kingdom.1252   
[3] LC_MONETARY=English_United Kingdom.1252
[4] LC_NUMERIC=C                           
[5] LC_TIME=English_United Kingdom.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] forcats_0.5.0      stringr_1.4.0      dplyr_1.0.2        purrr_0.3.4       
 [5] readr_1.4.0        tidyr_1.1.2        tibble_3.0.4       ggplot2_3.3.2     
 [9] tidyverse_1.3.0    fitdistrplus_1.1-3 survival_3.2-7     MASS_7.3-53       

loaded via a namespace (and not attached):
 [1] tidyselect_1.1.0 xfun_0.18        splines_4.0.3    haven_2.3.1     
 [5] lattice_0.20-41  colorspace_1.4-1 vctrs_0.3.4      generics_0.0.2  
 [9] htmltools_0.5.0  yaml_2.2.1       blob_1.2.1       rlang_0.4.8     
[13] later_1.1.0.1    pillar_1.4.6     withr_2.3.0      glue_1.4.2      
[17] DBI_1.1.0        dbplyr_1.4.4     readxl_1.3.1     modelr_0.1.8    
[21] lifecycle_0.2.0  cellranger_1.1.0 munsell_0.5.0    gtable_0.3.0    
[25] workflowr_1.6.2  rvest_0.3.6      evaluate_0.14    labeling_0.4.2  
[29] knitr_1.30       httpuv_1.5.5     fansi_0.4.1      broom_0.7.2     
[33] Rcpp_1.0.5       promises_1.1.1   backports_1.1.10 scales_1.1.1    
[37] jsonlite_1.7.1   farver_2.0.3     fs_1.5.0         hms_0.5.3       
[41] digest_0.6.25    stringi_1.5.3    grid_4.0.3       rprojroot_1.3-2 
[45] cli_2.1.0        tools_4.0.3      magrittr_1.5     crayon_1.3.4    
[49] whisker_0.4      pkgconfig_2.0.3  ellipsis_0.3.1   Matrix_1.2-18   
[53] xml2_1.3.2       reprex_0.3.0     lubridate_1.7.9  httr_1.4.2      
[57] assertthat_0.2.1 rmarkdown_2.4    rstudioapi_0.11  R6_2.4.1        
[61] git2r_0.28.0     compiler_4.0.3  </code></pre>
</div>


<!-- Adjust MathJax settings so that all math formulae are shown using
TeX fonts only; see
http://docs.mathjax.org/en/latest/configuration.html.  This will make
the presentation more consistent at the cost of the webpage sometimes
taking slightly longer to load. Note that this only works because the
footer is added to webpages before the MathJax javascript. -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
